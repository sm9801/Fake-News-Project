{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2598d92c",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- Apply sentiment analysis\n",
    "- news article -> model -> { fakeNews: false, sentiment: 0.23 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4b6e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     /Users/samuelseokyukim/nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/samuelseokyukim/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('subjectivity')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee61cd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('news.csv')\n",
    "\n",
    "# Get shape and head\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04c17cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the labels\n",
    "labels = df.label\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07aaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['text'], labels, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a34330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through test set and clean each article\n",
    "\n",
    "cleaned_articles = []\n",
    "\n",
    "for document in x_test :\n",
    "    # Remove all the special characters\n",
    "    noSpecial = re.sub(r'\\W', ' ', document)\n",
    "\n",
    "    # Remove all single characters\n",
    "    #noSingle = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', noSpecial)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    #noSingleFromStart = re.sub(r'\\^[a-zA-Z]\\s+', ' ', noSingle) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    noMultiSpace = re.sub(r'\\s+', ' ', noSpecial, flags = re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    noPrefixed = re.sub(r'^b\\s+', '', noMultiSpace)\n",
    "\n",
    "    # Convert to Lowercase\n",
    "    lowercased = noPrefixed.lower()\n",
    "    \n",
    "    cleaned_articles.append(lowercased)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c7480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nn_instances = 100\\n\\n# Gather a list of subjective words and a list of objective words\\nsubj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories = 'subj')[:n_instances]]\\nobj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories = 'obj')[:n_instances]]\\nlen(subj_docs), len(obj_docs)\\n\\n# Split subjective and objective instances \\ntrain_subj_docs = subj_docs[:80]\\ntest_subj_docs = subj_docs[80:100]\\ntrain_obj_docs = obj_docs[:80]\\ntest_obj_docs = obj_docs[80:100]\\ntraining_docs = train_subj_docs + train_obj_docs\\ntesting_docs = test_subj_docs + test_obj_docs\\n\\n# Initialize sentiment analyzer\\nsentim_analyzer = SentimentAnalyzer()\\nall_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\\n\\n# Unigram word features handle negation\\nunigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq = 4)\\nprint(len(unigram_feats))\\nsentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\\n\\n# Apply features to obtain a feature-value representation\\ntraining_set = sentim_analyzer.apply_features(training_docs)\\ntest_set = sentim_analyzer.apply_features(testing_docs)\\n\\n# Train the classifier on the training_set\\ntrainer = NaiveBayesClassifier.train\\nclassifier = sentim_analyzer.train(trainer, training_set)\\n\\n# Output evaluation results\\nfor key, value in sorted(sentim_analyzer.evaluate(test_set).items()):\\n    print('{0}: {1}'.format(key, value))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another method of applying sentiment analysis (unfinished)\n",
    "\n",
    "\"\"\"\n",
    "n_instances = 100\n",
    "\n",
    "# Gather a list of subjective words and a list of objective words\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories = 'subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories = 'obj')[:n_instances]]\n",
    "len(subj_docs), len(obj_docs)\n",
    "\n",
    "# Split subjective and objective instances \n",
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "training_docs = train_subj_docs + train_obj_docs\n",
    "testing_docs = test_subj_docs + test_obj_docs\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
    "\n",
    "# Unigram word features handle negation\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq = 4)\n",
    "print(len(unigram_feats))\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
    "\n",
    "# Apply features to obtain a feature-value representation\n",
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)\n",
    "\n",
    "# Train the classifier on the training_set\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "\n",
    "# Output evaluation results\n",
    "for key, value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a list of strings and pandas dataframe\n",
    "# Loop through each element in list or dataframe \n",
    "# Applies sentiment analysis\n",
    "def sentiment_analysis(articles_list) :\n",
    "    \n",
    "    for article in articles_list :\n",
    "        \n",
    "        # Initialize sentiment intensity analyzer\n",
    "        sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Print(article)\n",
    "        results = sentiment_analyzer.polarity_scores(article)\n",
    "        print('Sentiment analysis results: ')\n",
    "        \n",
    "        for k in sorted(results) :\n",
    "            print('{0}: {1}, '.format(k, results[k]), end = '')\n",
    "        print()\n",
    "        \n",
    "        print(\"Article was rated as\", results['neg'] * 100, \"% Negative\")\n",
    "        print(\"Article was rated as\", results['neu'] * 100, \"% Neutral\")\n",
    "        print(\"Article was rated as\", results['pos'] * 100, \"% Positive\")\n",
    "        print(\"Overall rating of the article:\", end = ' ')\n",
    "        \n",
    "        # Determine if an article is overall positive, negative, or neutral\n",
    "        if results['compound'] >= 0.05 :\n",
    "            print(\"Positive\")\n",
    " \n",
    "        elif results['compound'] <= - 0.05 :\n",
    "            print(\"Negative\")\n",
    " \n",
    "        else :\n",
    "            print(\"Neutral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0f5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.7)\n",
    "\n",
    "# Fit and transform train set, transform test set\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(cleaned_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dee6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test: 92.98%\n"
     ]
    }
   ],
   "source": [
    "# Initialize PassiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier(max_iter = 50)\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of test: {round(score * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54104590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[587,  42],\n",
       "       [ 47, 591]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build confusion matrix: [[true positive, false negative], [false positive, true negative]]\n",
    "confusion_matrix(y_test, y_pred, labels = ['REAL', 'FAKE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d29b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: FAKE\n",
      "Accuracy of the results: 100.0%\n",
      "Sentiment analysis results: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8k/2rzp_x8d70j7w5wzcmn8flrc0000gn/T/ipykernel_2767/4065905576.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Apply sentiment analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8k/2rzp_x8d70j7w5wzcmn8flrc0000gn/T/ipykernel_2767/2444077558.py\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(articles_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sentiment analysis results: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}: {1}, '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "# Test a random article from CNN\n",
    "expected_y = ['FAKE']\n",
    "x_test_1 = ['SEYMOUR, IN—Calling into question the 9-year-old amateur geologist’s taste and expertise, sources confirmed Thursday that local child Jacob Hiller could afford to be more discerning about which rocks were worth collecting. “I asked him what kind of rock this one was and he said ‘shiny’—shiny isn’t a rock type, moron,” said one source, who noted that the majority of the rocks in the boy’s collection came either from his backyard or the drainage ditch along the side of the road, neither of which seemed like particularly impressive dig sites. “Oh, this one is bigger than that one? Is that your hypothesis? Does he not realize this one is literally a chunk of concrete? Even the few cool-looking rocks he does own are fakes; they’re tumbled and dyed. He might know rocks can’t naturally be that shiny and magenta if he’d bothered to read one goddamn article on geology in his entire life.” At press time, the child had reportedly added an invaluable dinosaur fossil to the collection in his shirt.']\n",
    "tfidf_test_1 = tfidf_vectorizer.transform(x_test_1)\n",
    "actual_y = pac.predict(tfidf_test_1)\n",
    "score_1 = accuracy_score(expected_y, actual_y)\n",
    "\n",
    "if expected_y == actual_y :\n",
    "    print(\"Results:\", actual_y[0])\n",
    "\n",
    "elif expected_y == ['FAKE'] and actual_y == ['REAL'] :\n",
    "    print(\"Results are false positive: news is considered real when it isn't\")\n",
    "\n",
    "elif expected_y == ['REAL'] and actual_y == ['FAKE'] :\n",
    "    print(\"Results are false negative: news is considered fake when it isn't\")\n",
    "\n",
    "print(f'Accuracy of the results: {round(score_1 * 100, 2)}%')\n",
    "\n",
    "# Apply sentiment analysis\n",
    "sentiment_analysis(x_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c32068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix of the random article \n",
    "confusion_matrix(expected_y, actual_y, labels = ['REAL', 'FAKE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e42ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(actual_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d801ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
